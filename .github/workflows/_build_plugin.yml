name: build-cuda-plugin
on:
  workflow_call:
    inputs:
      dev-image:
        required: true
        type: string
        description: Base image for builds
      runner:
        required: false
        type: string
        description: Runner type for the test
        default: linux.12xlarge
      cuda:
        required: false
        type: string
        description: Whether to build XLA with CUDA
        default: 1

    secrets:
      gcloud-service-key:
        required: true
        description: Secret to access Bazel build cache

    outputs:
      docker-image:
        value: ${{ jobs.build.outputs.docker-image }}
        description: The docker image containing the built PyTorch.
jobs:
  build:
    runs-on: ${{ inputs.runner }}
    container:
      image: ${{ inputs.dev-image }}
    env:
      GCLOUD_SERVICE_KEY: ${{ secrets.gcloud-service-key }}
      GOOGLE_APPLICATION_CREDENTIALS: /tmp/default_credentials.json
      BAZEL_JOBS: 16
      BAZEL_REMOTE_CACHE: 1
      # TODO: Should also come from ansible
      TF_CUDA_COMPUTE_CAPABILITIES: 7.0,7.5,8.0,9.0
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
      - name: Setup gcloud
        shell: bash
        run: |
          echo "${GCLOUD_SERVICE_KEY}" > $GOOGLE_APPLICATION_CREDENTIALS
      - name: Build
        shell: bash
        run: |
          mkdir dist
          # TODO: Use current checkout with ansible instead
          pip wheel --no-deps -w dist -v plugins/cuda
      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: cuda-plugin
          path: ${{ github.workspace }}/dist/*.whl
