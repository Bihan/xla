name: xla-test-requiring-torch-cuda
on:
  workflow_call:
    inputs:
      dev-image:
        required: true
        type: string
        description: Base image for builds
      runner:
        required: false
        type: string
        description: Runner type for the test
        default: linux.12xlarge
      collect-coverage:
        required: false
        type: boolean
        description: Set to true to collect coverage information
        default: false
      timeout-minutes:
        required: false
        type: number
        default: 270
        description: |
          Set the maximum (in minutes) how long the workflow should take to finish
            timeout-minutes:

    secrets:
      gcloud-service-key:
        required: true
        description: Secret to access Bazel build cache
jobs:
  test:
    runs-on: ${{ inputs.runner }}
    container:
      image: ${{ inputs.dev-image }}
      options: "--gpus all --shm-size 16g"
    timeout-minutes: ${{ inputs.timeout-minutes }}
    env:
      GCLOUD_SERVICE_KEY: ${{ secrets.gcloud-service-key }}
      GOOGLE_APPLICATION_CREDENTIALS: /tmp/default_credentials.json
      USE_COVERAGE: ${{ inputs.collect-coverage && '1' || '0' }}
      BAZEL_JOBS: 16
      BAZEL_REMOTE_CACHE: 1
    steps:
      # See https://github.com/actions/checkout/issues/1014#issuecomment-1906802802
      - name: Clean up workspace
        run: |
          ls -la
          rm -rvf ${GITHUB_WORKSPACE}/*
      - name: Setup gcloud
        shell: bash
        run: |
          echo "${GCLOUD_SERVICE_KEY}" > $GOOGLE_APPLICATION_CREDENTIALS
      - name: Fetch torch wheel with CUDA enabled
        uses: actions/download-artifact@v4
        with:
          name: torch-with-cuda-xla-with-cuda-wheels
          path: /tmp/wheels/
          pattern: torch-*.whl 
      - name: Fetch torch_xla (without CUDA enabled) and torchvision wheel.
        uses: actions/download-artifact@v4
        with:
          name: torch-xla-wheels
          path: /tmp/wheels/
          pattern: (torch_xla-*.whl|torchvision*.whl)
      - name: Fetch CUDA plugin
        uses: actions/download-artifact@v4
        with:
          name: cuda-plugin
          path: /tmp/wheels/
      - name: Setup CUDA environment
        shell: bash
        run: |
          # TODO: Make PJRT_DEVICE=CPU work with XLA_REGISTER_INSTALLED_PLUGINS=1
          echo "XLA_REGISTER_INSTALLED_PLUGINS=1" >> $GITHUB_ENV

          echo "PATH=$PATH:/usr/local/cuda-12.1/bin" >> $GITHUB_ENV
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-12.1/lib64" >> $GITHUB_ENV
      - name: Check GPU
        run: nvidia-smi
      - name: Install wheels
        shell: bash
        run: |
          pip install /tmp/wheels/*.whl
          # TODO: Add these in setup.py
          pip install fsspec
          pip install rich

          echo "Import check..."
          python -c "import torch_xla"
          echo "Import check done."
          echo "Check if CUDA is available for PyTorch..."
          python -c "import torch; print('torch.cuda.is_available()=', torch.cuda.is_available())"
          echo "CUDA is available for PyTorch."
      - name: Record PyTorch commit
        run: |
          # Don't just pipe output in shell because imports may do extra logging
          python -c "
          import torch_xla.version
          with open('$GITHUB_ENV', 'a') as f:
            f.write(f'PYTORCH_COMMIT={torch_xla.version.__torch_gitrev__}\n')
          "
      - name: Checkout PyTorch Repo
        uses: actions/checkout@v4
        with:
          repository: pytorch/pytorch
          path: pytorch
          ref: ${{ env.PYTORCH_COMMIT }}
      - name: Checkout PyTorch/XLA Repo
        uses: actions/checkout@v4
        with:
          path: pytorch/xla
      - name: Extra CI deps
        shell: bash
        run: |
          set -x

          pip install expecttest unittest-xml-reporting
      - name: Test
        shell: bash
        run: |
          set -xue
          PJRT_DEVICE=CUDA python pytorch/xla/test/test_operations.py -v
          PJRT_DEVICE=CUDA python pytorch/xla/test/dynamo/test_dynamo.py -v
