name: build-cuda-plugin
on:
  workflow_call:
    inputs:
      dev-image:
        required: true
        type: string
        description: Base image for builds
      runner:
        required: false
        type: string
        description: Runner type for the test
        default: linux.12xlarge
      cuda:
        required: false
        type: string
        description: Whether to build XLA with CUDA
        default: 1

    secrets:
      gcloud-service-key:
        required: true
        description: Secret to access Bazel build cache

    outputs:
      docker-image:
        value: ${{ jobs.build.outputs.docker-image }}
        description: The docker image containing the built PyTorch.
jobs:
  build:
    runs-on: ${{ inputs.runner }}
    container:
      image: ${{ inputs.dev-image }}
    env:
      GCLOUD_SERVICE_KEY: ${{ secrets.gcloud-service-key }}
      GOOGLE_APPLICATION_CREDENTIALS: /tmp/default_credentials.json
      BAZEL_JOBS: 16
      BAZEL_REMOTE_CACHE: 1
    steps:
      - name: Setup gcloud
        shell: bash
        run: |
          echo "${GCLOUD_SERVICE_KEY}" > $GOOGLE_APPLICATION_CREDENTIALS
      - name: Checkout PyTorch Repo
        uses: actions/checkout@v4
        with:
          repository: pytorch/pytorch
          # TODO: correct pin
      - name: Checkout PyTorch/XLA Repo
        uses: actions/checkout@v4
        with:
          path: pytorch/xla
      - name: Build
        shell: bash
        run: |
          cd infra/ansible
          ansible-playbook playbook.yaml -e "stage=build arch=amd64 accelerator=tpu src_root=${GITHUB_WORKSPACE}" --skip-tags=fetch_srcs,install_deps
      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: torch-xla-wheel
          path: /dist/*.whl
